{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import butter, filtfilt, iirnotch, cheby2\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import pywt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lightning import Fabric\n",
    "import yaml\n",
    "import lightning\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from einops import repeat\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from classification.loaders import EEGDataset,load_data\n",
    "from models.unet.eeg_unets import Unet,UnetConfig, BottleNeckClassifier, Unet1D\n",
    "from classification.classifiers import DeepClassifier\n",
    "from classification.loaders import subject_dataset, CSP_subject_dataset\n",
    "from classification.open_bci_loaders import OpenBCIDataset,OpenBCISubject,load_files\n",
    "from ntd.networks import LongConv\n",
    "from ntd.diffusion_model import Diffusion\n",
    "from ntd.utils.kernels_and_diffusion_utils import WhiteNoiseProcess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "FS = 250\n",
    "sns.set_style(\"darkgrid\")\n",
    "DATA_PATH = \"../../data/2b_iv\"\n",
    "SAVE_PATH = \"../../saved_models/raw_eeg\"\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "\tos.makedirs(SAVE_PATH)\n",
    "CONF_PATH = \"../diffusion/conf\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CONF_PATH, \"train.yaml\"), \"r\") as f:\n",
    "    train_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"classifier.yaml\"), \"r\") as f:\n",
    "    classifier_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"network.yaml\"), \"r\") as f:\n",
    "    network_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"diffusion.yaml\"), \"r\") as f:\n",
    "    diffusion_yaml = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"results/params/best_tiny.json\",\"r\") as f:\n",
    "\tbest_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_channel': 64, 'kernel_size': 65, 'num_scales': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 2, 512)\n",
      "(4560,)\n",
      "final data shape: (4560, 2, 512)\n",
      "(707, 2, 512)\n",
      "(707,)\n",
      "final data shape: (707, 2, 512)\n",
      "(4560, 2, 512)\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "for i in range(1,10):\n",
    "    mat_train,mat_test = load_data(\"../../data/2b_iv\",i)\n",
    "    dataset[f\"subject_{i}\"] = {\"train\":mat_train,\"test\":mat_test}\n",
    "\n",
    "REAL_DATA = \"../../data/2b_iv/raw\"\n",
    "\n",
    "TRAIN_SPLIT = 6*[[\"train\",\"test\"]] + 3*[[\"train\"]]\n",
    "TEST_SPLIT = 6*[[]] + 3* [[\"test\"]]\n",
    "\n",
    "CHANNELS = [0,2]\n",
    "\n",
    "train_dataset = EEGDataset(subject_splits=TRAIN_SPLIT,\n",
    "                    dataset=None,\n",
    "                    save_paths=[REAL_DATA],\n",
    "                    subject_dataset_type=subject_dataset,\n",
    "                    channels=CHANNELS,\n",
    "                    sanity_check=False,\n",
    "                    length=2.05)\n",
    "\n",
    "test_dataset = EEGDataset(subject_splits=TEST_SPLIT,\n",
    "                    dataset=None,\n",
    "                    save_paths=[REAL_DATA],\n",
    "                    channels=CHANNELS,\n",
    "                    sanity_check=False,\n",
    "                    length=2.05)\n",
    "\n",
    "print(train_dataset.data[0].shape)\n",
    "network_yaml[\"signal_length\"] = train_dataset.data[0].shape[-1]\n",
    "network_yaml[\"signal_channel\"] = train_dataset.data[0].shape[1]\n",
    "print(network_yaml[\"signal_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path d:\\Machine learning\\MI SSL\\motor-imagery-classification-2024\\models\\diffusion\n",
      "Saving new data\n",
      "(1984, 2, 512)\n",
      "(1984,)\n",
      "final data shape: (1984, 2, 512)\n",
      "Loading saved data\n",
      "(992, 2, 512)\n",
      "(992,)\n",
      "final data shape: (992, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"path {os.getcwd()}\")\n",
    "files = load_files(\"../../data/collected_data/\")\n",
    "train_split = 2*[[\"train\"]]\n",
    "test_split = 2*[[\"test\"]]\n",
    "save_path = os.path.join(\"processed\",\"raw\")\n",
    "csp_save_path = os.path.join(\"processed\",\"data/collected_data/csp\")\n",
    "\n",
    "train_csp_dataset = OpenBCIDataset(\n",
    "\tsubject_splits=train_split,\n",
    "\tdataset=files,\n",
    "\tsave_paths=[save_path],\n",
    "\tfake_data=None,\n",
    "\tdataset_type=OpenBCISubject,\n",
    "\tchannels=np.arange(0,2),\n",
    "\tsubject_channels=[\"ch2\",\"ch5\"],\n",
    "\tstride=25,\n",
    "\tepoch_length=512\n",
    ")\n",
    "\n",
    "test_csp_dataset = OpenBCIDataset(\n",
    "\tsubject_splits=test_split,\n",
    "\tsave_paths=[save_path],\n",
    "\tfake_data=None,\n",
    "\tdataset_type=OpenBCISubject,\n",
    "\tchannels=np.arange(0,2),\n",
    "\tsubject_channels=[\"ch2\",\"ch5\"],\n",
    "\tstride=25,\n",
    "\tepoch_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 6E-4\n",
    "num_epochs = 250\n",
    "time_dim = 12\n",
    "hidden_channel = best_params[\"hidden_channel\"]\n",
    "kernel_size = best_params[\"kernel_size\"]\n",
    "num_scales = best_params[\"num_scales\"]\n",
    "decay_min = 2\n",
    "decay_max = 2\n",
    "activation_type = \"leaky_relu\"\n",
    "use_fft_conv = kernel_size * (2 ** (num_scales - 1)) >= 100\n",
    "num_timesteps = 1000\n",
    "schedule = \"linear\"\n",
    "# If the schedule is not cosine, we need to test the end_beta\n",
    "start_beta = 0.0001\n",
    "end_beta = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LongConv(\n",
    "\t\t\tsignal_length=network_yaml[\"signal_length\"],\n",
    "\t\t\tsignal_channel=2, # The CSP classifier components\n",
    "\t\t\ttime_dim=time_dim,\n",
    "\t\t\tcond_channel=network_yaml[\"cond_channel\"], # The cond channel will contain the cue (0 or 1)\n",
    "\t\t\thidden_channel=hidden_channel,\n",
    "\t\t\tin_kernel_size=kernel_size,\n",
    "\t\t\tout_kernel_size=kernel_size,\n",
    "\t\t\tslconv_kernel_size=kernel_size,\n",
    "\t\t\tnum_scales=num_scales,\n",
    "\t\t\tdecay_min=decay_min,\n",
    "\t\t\tdecay_max=decay_max,\n",
    "\t\t\theads=network_yaml[\"heads\"],\n",
    "\t\t\tactivation_type=activation_type,\n",
    "\t\t\tuse_fft_conv=use_fft_conv,\n",
    "\t\t)\n",
    "\n",
    "noise_sampler = WhiteNoiseProcess(1.0, network_yaml[\"signal_length\"])\n",
    "\n",
    "diffusion_model = Diffusion(\n",
    "\tnetwork=network,\n",
    "\tdiffusion_time_steps=num_timesteps,\n",
    "\tnoise_sampler=noise_sampler,\n",
    "\tmal_dist_computer=noise_sampler,\n",
    "\tschedule=schedule,\n",
    "\tstart_beta=start_beta,\n",
    "\tend_beta=end_beta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "FABRIC = Fabric(accelerator=\"cuda\",precision=\"bf16-mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset,\n",
    "\ttrain_yaml[\"batch_size\"]\n",
    ")\n",
    "\n",
    "loss_per_epoch = []\n",
    "\n",
    "stop_counter = 0\n",
    "min_delta = 0.05\n",
    "tolerance = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_yaml[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fabric,diffusion_model,train_loader):\n",
    "\toptimizer = optim.AdamW(\n",
    "        network.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "\n",
    "\tdiffusion_model,optimizer = fabric.setup(diffusion_model,optimizer)\n",
    "\n",
    "\ttrain_loader = fabric.setup_dataloaders(train_loader)\n",
    "\tfor i in range(num_epochs):\n",
    "\t\t\t\n",
    "\t\t\tepoch_loss = []\n",
    "\t\t\tfor batch in train_loader:\n",
    "\t\t\t\t\n",
    "\t\t\t\twith fabric.autocast():\n",
    "\n",
    "\t\t\t\t\tsignal,cue = batch\n",
    "\t\t\t\t\tsignal = signal.to(torch.bfloat16)\n",
    "\t\t\t\t\tcue = cue.to(torch.bfloat16)\n",
    "\t\t\t\t\tcond = cue.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, network_yaml[\"signal_length\"]).to(DEVICE)\n",
    "\t\t\t\t\tloss = diffusion_model.train_batch(signal.to(DEVICE),\n",
    "\t\t\t\t\t\t\t\t\t\t cond=cond)\n",
    "\t\t\t\tloss = torch.mean(loss)\n",
    "\t\t\t\t\n",
    "\t\t\t\tepoch_loss.append(loss.item())\n",
    "\t\t\t\t\n",
    "\t\t\t\tfabric.backward(loss)\n",
    "\t\t\t\t# loss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\t\n",
    "\t\t\tepoch_loss = np.mean(epoch_loss)\n",
    "\t\t\tloss_per_epoch.append(epoch_loss)\n",
    "\n",
    "\t\t\tprint(f\"Epoch {i} loss: {epoch_loss}\")\n",
    "\n",
    "\t\t\tprint(f\"diff: {epoch_loss - min(loss_per_epoch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_train = lambda model,loader : train(FABRIC,model,loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric_train(diffusion_model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_model.load_state_dict(torch.load(\"results/saved_models/tiny_slc_2_channels.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  channels: Tuple[int],\n",
    "\t\t\t  pool=None) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.mlp = nn.ModuleList()\n",
    "\t\tfor i in range(len(channels)-1):\n",
    "\t\t\tself.mlp.append(nn.Linear(channels[i],channels[i+1]))\n",
    "\t\t\tself.mlp.append(nn.ReLU())\n",
    "\t\tself.mlp.append(nn.Linear(channels[-1],2))\n",
    "\t\tself.pool = pool\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx = x[...,-1]\n",
    "\t\tfor i in self.mlp:\n",
    "\t\t\tx = i(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNetHead(lightning.LightningModule):\n",
    "\tdef __init__(self,c_in,d_out):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.T = 120\n",
    "\t\t\n",
    "\t\t# Layer 1\n",
    "\t\tself.conv1 = nn.Conv2d(1, 16, (c_in, 1), padding = 0)\n",
    "\t\tself.norm1 = nn.BatchNorm2d(16, False)\n",
    "\t\t\n",
    "\t\t# Layer 2\n",
    "\t\tself.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "\t\tself.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "\t\tself.norm2 = nn.BatchNorm2d(4, False)\n",
    "\t\tself.pooling2 = nn.MaxPool2d(2, 4)\n",
    "\t\t\n",
    "\t\t# Layer 3\n",
    "\t\tself.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "\t\tself.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "\t\tself.norm3 = nn.BatchNorm2d(4, False)\n",
    "\t\tself.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\t\tself.out_proj = nn.Linear(d_out,2)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\n",
    "\t\tx = rearrange(x,\"b d t -> b 1 d t\")\n",
    "\t\t\n",
    "\t\t# Layer 1\n",
    "\t\tx = F.elu(self.conv1(x))\n",
    "\t\tx = self.norm1(x)\n",
    "\t\tx = F.dropout(x, 0.25)\n",
    "\t\tx = rearrange(x,\"b cond h w ->b h cond w\")\n",
    "\n",
    "\t\t# Layer 2\n",
    "\t\tx = self.padding1(x)\n",
    "\t\tx = F.elu(self.conv2(x))\n",
    "\t\tx = self.norm2(x)\n",
    "\t\tx = F.dropout(x, 0.25)\n",
    "\t\tx = self.pooling2(x)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# Layer 3\n",
    "\t\tx = self.padding2(x)\n",
    "\t\tx = F.elu(self.conv3(x))\n",
    "\t\tx = self.norm3(x)\n",
    "\t\tx = F.dropout(x, 0.25)\n",
    "\t\tx = self.pooling3(x)\n",
    "\n",
    "\t\tx = rearrange(x,\"b d1 d2 t -> b (d1 d2 t)\")\n",
    "\t\tx = self.out_proj(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegnet = EEGNetHead(128,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | Name     | Type        | Params\n",
       "------------------------------------------\n",
       "0  | conv1    | Conv2d      | 2.1 K \n",
       "1  | norm1    | BatchNorm2d | 32    \n",
       "2  | padding1 | ZeroPad2d   | 0     \n",
       "3  | conv2    | Conv2d      | 260   \n",
       "4  | norm2    | BatchNorm2d | 8     \n",
       "5  | pooling2 | MaxPool2d   | 0     \n",
       "6  | padding2 | ZeroPad2d   | 0     \n",
       "7  | conv3    | Conv2d      | 516   \n",
       "8  | norm3    | BatchNorm2d | 8     \n",
       "9  | pooling3 | MaxPool2d   | 0     \n",
       "10 | out_proj | Linear      | 514   \n",
       "------------------------------------------\n",
       "3.4 K     Trainable params\n",
       "0         Non-trainable params\n",
       "3.4 K     Total params\n",
       "0.014     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(eegnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionClf(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  model,\n",
    "\t\t\t  clf,\n",
    "\t\t\t  freeze=True):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = model.network\n",
    "\t\tif freeze:\n",
    "\t\t\tfor param in self.model.parameters():\n",
    "\t\t\t\tparam.requires_grad = False\n",
    "\t\tself.clf = clf\n",
    "\n",
    "\tdef forward(self,\n",
    "\t\t\t x):\n",
    "\n",
    "\t\tcond = torch.ones((x.shape[0],1,x.shape[-1]),device=self.device)\n",
    "\t\tx = torch.cat([x,cond],1)\n",
    "\t\tt = torch.zeros(len(x),device=self.device)\n",
    "\t\ttime_embed = self.model.time_embbeder(t)\n",
    "\t\ttime_embed = repeat(time_embed,\"b t -> b t l\",l=x.shape[-1])\n",
    "\t\tx = torch.cat([x,time_embed],1)\n",
    "\t\tx = self.model.conv_pool[0:-1](x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef classify(self,x):\n",
    "\n",
    "\t\tx = self.forward(x)\n",
    "\t\tx = self.clf(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ClassificationHead([128])\n",
    "eegnet_head = EEGNetHead(128,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DiffusionClf(diffusion_model,eegnet_head,freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name  | Type       | Params\n",
       "-------------------------------------\n",
       "0 | model | LongConv   | 443 K \n",
       "1 | clf   | EEGNetHead | 3.4 K \n",
       "-------------------------------------\n",
       "446 K     Trainable params\n",
       "0         Non-trainable params\n",
       "446 K     Total params\n",
       "1.786     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiffusionClf(\n",
       "  (model): LongConv(\n",
       "    (time_embbeder): SinusoidalPosEmb()\n",
       "    (conv_pool): Sequential(\n",
       "      (0): EfficientMaskedConv1d(\n",
       "        (layer): Conv1d(15, 128, kernel_size=(65,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): SLConv(\n",
       "        (kernel_list): ParameterList(\n",
       "            (0): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "            (1): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "        )\n",
       "      )\n",
       "      (4): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): EfficientMaskedConv1d(\n",
       "        (layer): Conv1d(384, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): LeakyReLU(negative_slope=0.01)\n",
       "      (9): SLConv(\n",
       "        (kernel_list): ParameterList(\n",
       "            (0): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "            (1): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "        )\n",
       "      )\n",
       "      (10): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): LeakyReLU(negative_slope=0.01)\n",
       "      (12): EfficientMaskedConv1d(\n",
       "        (layer): Conv1d(384, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): LeakyReLU(negative_slope=0.01)\n",
       "      (15): SLConv(\n",
       "        (kernel_list): ParameterList(\n",
       "            (0): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "            (1): Parameter containing: [torch.float32 of size 3x128x65 (GPU 0)]\n",
       "        )\n",
       "      )\n",
       "      (16): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): LeakyReLU(negative_slope=0.01)\n",
       "      (18): EfficientMaskedConv1d(\n",
       "        (layer): Conv1d(384, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
       "      )\n",
       "      (19): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (20): LeakyReLU(negative_slope=0.01)\n",
       "      (21): EfficientMaskedConv1d(\n",
       "        (layer): Conv1d(128, 2, kernel_size=(65,), stride=(1,), padding=same)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (clf): EEGNetHead(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
       "    (norm1): BatchNorm2d(16, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (padding1): ZeroPad2d((16, 17, 0, 1))\n",
       "    (conv2): Conv2d(1, 4, kernel_size=(2, 32), stride=(1, 1))\n",
       "    (norm2): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding2): ZeroPad2d((2, 1, 4, 3))\n",
       "    (conv3): Conv2d(4, 4, kernel_size=(8, 4), stride=(1, 1))\n",
       "    (norm3): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((16,2,512),device=clf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 512])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2626,  2.3540],\n",
       "        [ 1.7146,  2.0596],\n",
       "        [ 0.1287,  1.9347],\n",
       "        [ 1.2821,  1.9066],\n",
       "        [ 0.3995,  1.9177],\n",
       "        [ 0.8560,  2.3023],\n",
       "        [ 0.7173,  1.8159],\n",
       "        [ 1.2211,  1.5279],\n",
       "        [-0.1140, -0.0468],\n",
       "        [-0.1153,  1.6670],\n",
       "        [ 0.9307,  1.6229],\n",
       "        [ 1.4220,  1.7189],\n",
       "        [-0.3206,  1.9613],\n",
       "        [ 0.3001,  1.4987],\n",
       "        [ 1.2071,  1.2802],\n",
       "        [ 1.1532,  0.6494]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = \"../saved_models/raw_eeg/generated_ones.npy\"\n",
    "zeros = \"../saved_models/raw_eeg/generated_zeros.npy\"\n",
    "fake_paths = (ones,zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved data\n",
      "(416, 2, 512)\n",
      "(416,)\n",
      "final data shape: (416, 2, 512)\n",
      "Loading saved data\n",
      "(208, 2, 512)\n",
      "(208,)\n",
      "final data shape: (208, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "# slc_clf = DeepClassifier(\n",
    "# \tmodel=clf.to(DEVICE),\n",
    "# \tsave_paths=[\"../../data/2b_iv/raw/\"],\n",
    "# \tfake_data=None,\n",
    "# \ttrain_split=TRAIN_SPLIT,\n",
    "# \ttest_split=TEST_SPLIT,\n",
    "# \tdataset=None,\n",
    "# \tsubject_dataset_type=subject_dataset,\n",
    "# \tlength=2.05,\n",
    "# \tindex_cutoff=512\n",
    "# )\n",
    "\n",
    "slc_clf = DeepClassifier(\n",
    "\tmodel=clf.to(DEVICE),\n",
    "\tsave_paths=[csp_save_path],\n",
    "\tfake_data=None,\n",
    "\ttrain_split=train_split,\n",
    "\ttest_split=test_split,\n",
    "\tdataset=None,\n",
    "\tdataset_type=OpenBCIDataset,\n",
    "\tsubject_dataset_type=OpenBCISubject,\n",
    "\tchannels=np.arange(0,2),\n",
    "\tsubject_channels=[\"ch2\",\"ch5\"],\n",
    "\tlength=2.0,\n",
    "\tepoch_length=512,\n",
    "\tindex_cutoff=512\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW([\n",
    "\t{\"params\":slc_clf.model.model.parameters(),\"lr\":2E-5,\"weight_decay\":1E-4},\n",
    "\t{\"params\":slc_clf.model.clf.parameters(),\"lr\":1E-3,\"weight_decay\":1E-4}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using specified optimizer\n",
      "checkpointing\n",
      "Epoch [1/25], Training Loss: 0.707, Training Accuracy: 56.56%, Validation Loss: 0.588, Validation Accuracy: 68.84%\n",
      "Min loss: 0.5877278645833334 vs 0.58984375\n",
      "Epoch [2/25], Training Loss: 0.647, Training Accuracy: 62.24%, Validation Loss: 0.590, Validation Accuracy: 69.69%\n",
      "Min loss: 0.5877278645833334 vs 0.60205078125\n",
      "Epoch [3/25], Training Loss: 0.614, Training Accuracy: 65.79%, Validation Loss: 0.602, Validation Accuracy: 66.57%\n",
      "Min loss: 0.5877278645833334 vs 0.6100260416666666\n",
      "Epoch [4/25], Training Loss: 0.579, Training Accuracy: 69.28%, Validation Loss: 0.610, Validation Accuracy: 74.22%\n",
      "checkpointing\n",
      "Epoch [5/25], Training Loss: 0.559, Training Accuracy: 71.64%, Validation Loss: 0.495, Validation Accuracy: 73.65%\n",
      "Min loss: 0.4951171875 vs 0.4990234375\n",
      "Epoch [6/25], Training Loss: 0.532, Training Accuracy: 73.29%, Validation Loss: 0.499, Validation Accuracy: 75.64%\n",
      "Min loss: 0.4951171875 vs 0.5245768229166666\n",
      "Epoch [7/25], Training Loss: 0.521, Training Accuracy: 73.33%, Validation Loss: 0.525, Validation Accuracy: 79.04%\n",
      "checkpointing\n",
      "Epoch [8/25], Training Loss: 0.495, Training Accuracy: 75.31%, Validation Loss: 0.443, Validation Accuracy: 80.74%\n",
      "checkpointing\n",
      "Epoch [9/25], Training Loss: 0.487, Training Accuracy: 76.25%, Validation Loss: 0.411, Validation Accuracy: 78.47%\n",
      "Min loss: 0.4112141927083333 vs 0.4495442708333333\n",
      "Epoch [10/25], Training Loss: 0.485, Training Accuracy: 75.92%, Validation Loss: 0.450, Validation Accuracy: 77.90%\n",
      "Min loss: 0.4112141927083333 vs 0.52392578125\n",
      "Epoch [11/25], Training Loss: 0.467, Training Accuracy: 77.54%, Validation Loss: 0.524, Validation Accuracy: 80.17%\n",
      "Min loss: 0.4112141927083333 vs 0.4192708333333333\n",
      "Epoch [12/25], Training Loss: 0.463, Training Accuracy: 77.74%, Validation Loss: 0.419, Validation Accuracy: 81.59%\n",
      "Min loss: 0.4112141927083333 vs 0.529296875\n",
      "Epoch [13/25], Training Loss: 0.463, Training Accuracy: 77.24%, Validation Loss: 0.529, Validation Accuracy: 75.35%\n",
      "Min loss: 0.4112141927083333 vs 0.41455078125\n",
      "Epoch [14/25], Training Loss: 0.451, Training Accuracy: 78.11%, Validation Loss: 0.415, Validation Accuracy: 78.47%\n",
      "checkpointing\n",
      "Epoch [15/25], Training Loss: 0.447, Training Accuracy: 78.33%, Validation Loss: 0.398, Validation Accuracy: 82.15%\n",
      "Min loss: 0.3984375 vs 0.4728190104166667\n",
      "Epoch [16/25], Training Loss: 0.443, Training Accuracy: 78.60%, Validation Loss: 0.473, Validation Accuracy: 79.89%\n",
      "Min loss: 0.3984375 vs 0.4024251302083333\n",
      "Epoch [17/25], Training Loss: 0.443, Training Accuracy: 78.18%, Validation Loss: 0.402, Validation Accuracy: 80.74%\n",
      "Min loss: 0.3984375 vs 0.4251302083333333\n",
      "Epoch [18/25], Training Loss: 0.435, Training Accuracy: 79.69%, Validation Loss: 0.425, Validation Accuracy: 80.17%\n",
      "Min loss: 0.3984375 vs 0.406982421875\n",
      "Epoch [19/25], Training Loss: 0.426, Training Accuracy: 79.32%, Validation Loss: 0.407, Validation Accuracy: 81.59%\n",
      "Min loss: 0.3984375 vs 0.4414876302083333\n",
      "Epoch [20/25], Training Loss: 0.434, Training Accuracy: 79.76%, Validation Loss: 0.441, Validation Accuracy: 79.32%\n",
      "Min loss: 0.3984375 vs 0.4097696940104167\n",
      "Epoch [21/25], Training Loss: 0.423, Training Accuracy: 80.48%, Validation Loss: 0.410, Validation Accuracy: 81.02%\n",
      "Min loss: 0.3984375 vs 0.4148763020833333\n",
      "Epoch [22/25], Training Loss: 0.419, Training Accuracy: 80.02%, Validation Loss: 0.415, Validation Accuracy: 79.32%\n",
      "Min loss: 0.3984375 vs 0.4558919270833333\n",
      "Epoch [23/25], Training Loss: 0.411, Training Accuracy: 80.46%, Validation Loss: 0.456, Validation Accuracy: 80.45%\n",
      "Min loss: 0.3984375 vs 0.4412027994791667\n",
      "Epoch [24/25], Training Loss: 0.407, Training Accuracy: 81.12%, Validation Loss: 0.441, Validation Accuracy: 79.32%\n",
      "Min loss: 0.3984375 vs 0.42626953125\n",
      "Epoch [25/25], Training Loss: 0.403, Training Accuracy: 81.51%, Validation Loss: 0.426, Validation Accuracy: 80.74%\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.15297450424929"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slc_clf.fit(fabric=FABRIC,\n",
    "\t\t\t num_epochs=25,\n",
    "\t\t\t lr=1E-3,\n",
    "\t\t\t weight_decay=1E-4,\n",
    "\t\t\t verbose=True,\n",
    "\t\t\t optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 73.7 test when only using the last token and 1 second\n",
    "- 83.85 for EEGNet classification head on 2 seconds and 3 channels\n",
    "- 82.15 for EEGNet classification head on 2 seconds and 2 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
