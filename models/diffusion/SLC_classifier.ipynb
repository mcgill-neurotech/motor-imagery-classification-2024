{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahar\\anaconda3\\envs\\neuro\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import butter, filtfilt, iirnotch, cheby2\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import pywt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lightning import Fabric\n",
    "import yaml\n",
    "import lightning\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from einops import repeat\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from classification.loaders import EEGDataset,load_data\n",
    "from models.unet.eeg_unets import Unet,UnetConfig, BottleNeckClassifier, Unet1D\n",
    "from classification.classifiers import DeepClassifier\n",
    "from classification.loaders import subject_dataset, CSP_subject_dataset\n",
    "from ntd.networks import LongConv\n",
    "from ntd.diffusion_model import Diffusion\n",
    "from ntd.utils.kernels_and_diffusion_utils import WhiteNoiseProcess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "FS = 250\n",
    "sns.set_style(\"darkgrid\")\n",
    "DATA_PATH = \"../../data/2b_iv\"\n",
    "SAVE_PATH = \"../../saved_models/raw_eeg\"\n",
    "if not os.path.isdir(SAVE_PATH):\n",
    "\tos.makedirs(SAVE_PATH)\n",
    "CONF_PATH = \"../diffusion/conf\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CONF_PATH, \"train.yaml\"), \"r\") as f:\n",
    "    train_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"classifier.yaml\"), \"r\") as f:\n",
    "    classifier_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"network.yaml\"), \"r\") as f:\n",
    "    network_yaml = yaml.safe_load(f)\n",
    "    \n",
    "with open(os.path.join(CONF_PATH, \"diffusion.yaml\"), \"r\") as f:\n",
    "    diffusion_yaml = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"params_2024_05_06_03_41.json\",\"r\") as f:\n",
    "\tbest_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 3, 512)\n",
      "(4560,)\n",
      "final data shape: (4560, 3, 512)\n",
      "(707, 3, 512)\n",
      "(707,)\n",
      "final data shape: (707, 3, 512)\n",
      "(4560, 3, 512)\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "for i in range(1,10):\n",
    "    mat_train,mat_test = load_data(\"../../data/2b_iv\",i)\n",
    "    dataset[f\"subject_{i}\"] = {\"train\":mat_train,\"test\":mat_test}\n",
    "\n",
    "REAL_DATA = \"../../data/2b_iv/raw\"\n",
    "\n",
    "TRAIN_SPLIT = 6*[[\"train\",\"test\"]] + 3*[[\"train\"]]\n",
    "TEST_SPLIT = 6*[[]] + 3* [[\"test\"]]\n",
    "\n",
    "CHANNELS = [0,1,2]\n",
    "\n",
    "train_dataset = EEGDataset(subject_splits=TRAIN_SPLIT,\n",
    "                    dataset=None,\n",
    "                    save_paths=[REAL_DATA],\n",
    "                    dataset_type=subject_dataset,\n",
    "                    channels=CHANNELS,\n",
    "                    sanity_check=False,\n",
    "                    length=2.05)\n",
    "\n",
    "test_dataset = EEGDataset(subject_splits=TEST_SPLIT,\n",
    "                    dataset=None,\n",
    "                    save_paths=[REAL_DATA],\n",
    "                    channels=CHANNELS,\n",
    "                    sanity_check=False,\n",
    "                    length=2.05)\n",
    "\n",
    "print(train_dataset.data[0].shape)\n",
    "network_yaml[\"signal_length\"] = train_dataset.data[0].shape[-1]\n",
    "network_yaml[\"signal_channel\"] = train_dataset.data[0].shape[1]\n",
    "print(network_yaml[\"signal_length\"])\n",
    "with open(r\"params_2024_05_06_03_41.json\",\"r\") as f:\n",
    "\tbest_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 6E-4\n",
    "num_epochs = 180\n",
    "time_dim = 12\n",
    "hidden_channel = best_params[\"hidden_channel\"]\n",
    "kernel_size = best_params[\"kernel_size\"]\n",
    "num_scales = best_params[\"num_scales\"]\n",
    "decay_min = 2\n",
    "decay_max = 2\n",
    "activation_type = \"leaky_relu\"\n",
    "use_fft_conv = kernel_size * (2 ** (num_scales - 1)) >= 100\n",
    "num_timesteps = 250\n",
    "schedule = \"linear\"\n",
    "# If the schedule is not cosine, we need to test the end_beta\n",
    "start_beta = 0.0001\n",
    "end_beta = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LongConv(\n",
    "\t\t\tsignal_length=network_yaml[\"signal_length\"],\n",
    "\t\t\tsignal_channel=network_yaml[\"signal_channel\"], # The CSP classifier components\n",
    "\t\t\ttime_dim=time_dim,\n",
    "\t\t\tcond_channel=network_yaml[\"cond_channel\"], # The cond channel will contain the cue (0 or 1)\n",
    "\t\t\thidden_channel=hidden_channel,\n",
    "\t\t\tin_kernel_size=kernel_size,\n",
    "\t\t\tout_kernel_size=kernel_size,\n",
    "\t\t\tslconv_kernel_size=kernel_size,\n",
    "\t\t\tnum_scales=num_scales,\n",
    "\t\t\tdecay_min=decay_min,\n",
    "\t\t\tdecay_max=decay_max,\n",
    "\t\t\theads=network_yaml[\"heads\"],\n",
    "\t\t\tactivation_type=activation_type,\n",
    "\t\t\tuse_fft_conv=use_fft_conv,\n",
    "\t\t)\n",
    "\n",
    "noise_sampler = WhiteNoiseProcess(1.0, network_yaml[\"signal_length\"])\n",
    "\n",
    "diffusion_model = Diffusion(\n",
    "\tnetwork=network,\n",
    "\tdiffusion_time_steps=num_timesteps,\n",
    "\tnoise_sampler=noise_sampler,\n",
    "\tmal_dist_computer=noise_sampler,\n",
    "\tschedule=schedule,\n",
    "\tstart_beta=start_beta,\n",
    "\tend_beta=end_beta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_model.load_state_dict(torch.load(\"../../saved_models/raw_eeg/best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  channels: Tuple[int],\n",
    "\t\t\t  pool=None) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.mlp = nn.ModuleList()\n",
    "\t\tfor i in range(len(channels)-1):\n",
    "\t\t\tself.mlp.append(nn.Linear(channels[i],channels[i+1]))\n",
    "\t\t\tself.mlp.append(nn.ReLU())\n",
    "\t\tself.mlp.append(nn.Linear(channels[-1],2))\n",
    "\t\tself.pool = pool\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx = x[...,-1]\n",
    "\t\tfor i in self.mlp:\n",
    "\t\t\tx = i(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionClf(lightning.LightningModule):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t\t\t  model,\n",
    "\t\t\t  clf,\n",
    "\t\t\t  freeze=True):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = model.network\n",
    "\t\tif freeze:\n",
    "\t\t\tfor param in self.model.parameters():\n",
    "\t\t\t\tparam.requires_grad = False\n",
    "\t\tself.clf = clf\n",
    "\n",
    "\tdef forward(self,\n",
    "\t\t\t x):\n",
    "\n",
    "\t\tcond = torch.ones((x.shape[0],1,x.shape[-1]),device=self.device)\n",
    "\t\tx = torch.cat([x,cond],1)\n",
    "\t\tt = torch.zeros(len(x),device=self.device)\n",
    "\t\ttime_embed = self.model.time_embbeder(t)\n",
    "\t\ttime_embed = repeat(time_embed,\"b t -> b t l\",l=x.shape[-1])\n",
    "\t\tx = torch.cat([x,time_embed],1)\n",
    "\t\tx = self.model.conv_pool[0:-1](x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef classify(self,x):\n",
    "\n",
    "\t\tx = self.forward(x)\n",
    "\t\tx = self.clf(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = ClassificationHead((96,2048,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DiffusionClf(diffusion_model,head,freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name  | Type               | Params\n",
       "---------------------------------------------\n",
       "0 | model | LongConv           | 429 K \n",
       "1 | clf   | ClassificationHead | 2.3 M \n",
       "---------------------------------------------\n",
       "2.7 M     Trainable params\n",
       "0         Non-trainable params\n",
       "2.7 M     Total params\n",
       "10.914    Total estimated model params size (MB)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSummary(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((16,3,512),device=clf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0821, 0.0669],\n",
       "        [0.0717, 0.0726],\n",
       "        [0.0799, 0.0768],\n",
       "        [0.0814, 0.0790],\n",
       "        [0.0716, 0.0674],\n",
       "        [0.0899, 0.0723],\n",
       "        [0.0714, 0.0618],\n",
       "        [0.0791, 0.0774],\n",
       "        [0.0791, 0.0589],\n",
       "        [0.0927, 0.0806],\n",
       "        [0.0801, 0.0686],\n",
       "        [0.0771, 0.0742],\n",
       "        [0.0952, 0.0835],\n",
       "        [0.0860, 0.0671],\n",
       "        [0.0871, 0.0705],\n",
       "        [0.0830, 0.0720]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = \"../saved_models/raw_eeg/generated_ones.npy\"\n",
    "zeros = \"../saved_models/raw_eeg/generated_zeros.npy\"\n",
    "fake_paths = (ones,zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4560, 3, 500)\n",
      "(4560,)\n",
      "final data shape: (4560, 3, 500)\n",
      "(707, 3, 500)\n",
      "(707,)\n",
      "final data shape: (707, 3, 500)\n"
     ]
    }
   ],
   "source": [
    "slc_clf = DeepClassifier(\n",
    "\tmodel=clf.to(DEVICE),\n",
    "\tsave_paths=[\"../../data/2b_iv/raw/\"],\n",
    "\tfake_data=None,\n",
    "\ttrain_split=TRAIN_SPLIT,\n",
    "\ttest_split=TEST_SPLIT,\n",
    "\tdataset=None,\n",
    "\tdataset_type=subject_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "fabric = Fabric(accelerator=\"cuda\",precision=\"bf16-mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW([\n",
    "\t{\"params\":slc_clf.model.model.parameters(),\"lr\":2E-5,\"weight_decay\":1E-4},\n",
    "\t{\"params\":slc_clf.model.clf.parameters(),\"lr\":1E-4,\"weight_decay\":1E-4}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using specified optimizer\n",
      "Epoch [1/150], Training Loss: 0.697, Training Accuracy: 50.20%, Validation Loss: 0.690, Validation Accuracy: 50.78%\n",
      "Epoch [2/150], Training Loss: 0.691, Training Accuracy: 52.74%, Validation Loss: 0.691, Validation Accuracy: 53.47%\n",
      "Epoch [3/150], Training Loss: 0.688, Training Accuracy: 54.19%, Validation Loss: 0.684, Validation Accuracy: 52.05%\n",
      "Epoch [4/150], Training Loss: 0.687, Training Accuracy: 55.46%, Validation Loss: 0.683, Validation Accuracy: 53.32%\n",
      "Epoch [5/150], Training Loss: 0.682, Training Accuracy: 56.01%, Validation Loss: 0.702, Validation Accuracy: 51.06%\n",
      "Epoch [6/150], Training Loss: 0.681, Training Accuracy: 56.86%, Validation Loss: 0.683, Validation Accuracy: 55.16%\n",
      "Epoch [7/150], Training Loss: 0.675, Training Accuracy: 57.81%, Validation Loss: 0.679, Validation Accuracy: 55.45%\n",
      "Epoch [8/150], Training Loss: 0.674, Training Accuracy: 57.68%, Validation Loss: 0.692, Validation Accuracy: 52.90%\n",
      "Epoch [9/150], Training Loss: 0.668, Training Accuracy: 58.93%, Validation Loss: 0.676, Validation Accuracy: 56.15%\n",
      "Epoch [10/150], Training Loss: 0.661, Training Accuracy: 60.22%, Validation Loss: 0.671, Validation Accuracy: 57.57%\n",
      "Epoch [11/150], Training Loss: 0.658, Training Accuracy: 61.07%, Validation Loss: 0.672, Validation Accuracy: 56.15%\n",
      "Epoch [12/150], Training Loss: 0.652, Training Accuracy: 61.10%, Validation Loss: 0.675, Validation Accuracy: 57.14%\n",
      "Epoch [13/150], Training Loss: 0.645, Training Accuracy: 62.70%, Validation Loss: 0.670, Validation Accuracy: 56.72%\n",
      "Epoch [14/150], Training Loss: 0.637, Training Accuracy: 63.40%, Validation Loss: 0.663, Validation Accuracy: 57.00%\n",
      "Epoch [15/150], Training Loss: 0.635, Training Accuracy: 63.29%, Validation Loss: 0.669, Validation Accuracy: 58.70%\n",
      "Epoch [16/150], Training Loss: 0.629, Training Accuracy: 64.36%, Validation Loss: 0.666, Validation Accuracy: 57.14%\n",
      "Epoch [17/150], Training Loss: 0.624, Training Accuracy: 64.47%, Validation Loss: 0.669, Validation Accuracy: 57.43%\n",
      "Epoch [18/150], Training Loss: 0.612, Training Accuracy: 66.25%, Validation Loss: 0.676, Validation Accuracy: 58.13%\n",
      "Epoch [19/150], Training Loss: 0.610, Training Accuracy: 66.14%, Validation Loss: 0.676, Validation Accuracy: 57.14%\n",
      "Epoch [20/150], Training Loss: 0.604, Training Accuracy: 66.69%, Validation Loss: 0.679, Validation Accuracy: 57.57%\n",
      "Epoch [21/150], Training Loss: 0.598, Training Accuracy: 67.41%, Validation Loss: 0.676, Validation Accuracy: 57.71%\n",
      "Epoch [22/150], Training Loss: 0.587, Training Accuracy: 69.06%, Validation Loss: 0.666, Validation Accuracy: 59.12%\n",
      "Epoch [23/150], Training Loss: 0.580, Training Accuracy: 69.19%, Validation Loss: 0.702, Validation Accuracy: 55.87%\n",
      "Epoch [24/150], Training Loss: 0.575, Training Accuracy: 68.93%, Validation Loss: 0.684, Validation Accuracy: 56.86%\n",
      "Epoch [25/150], Training Loss: 0.562, Training Accuracy: 70.66%, Validation Loss: 0.694, Validation Accuracy: 55.73%\n",
      "Epoch [26/150], Training Loss: 0.553, Training Accuracy: 71.05%, Validation Loss: 0.694, Validation Accuracy: 57.14%\n",
      "Epoch [27/150], Training Loss: 0.546, Training Accuracy: 71.86%, Validation Loss: 0.706, Validation Accuracy: 57.43%\n",
      "Epoch [28/150], Training Loss: 0.538, Training Accuracy: 72.08%, Validation Loss: 0.697, Validation Accuracy: 57.43%\n",
      "Epoch [29/150], Training Loss: 0.525, Training Accuracy: 74.21%, Validation Loss: 0.723, Validation Accuracy: 57.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mslc_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfabric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfabric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m\t\t\t \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m\t\t\t \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1E-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m\t\t\t \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1E-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m\t\t\t \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m\t\t\t \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Machine learning\\MI SSL\\motor-imagery-classification-2024\\models\\diffusion\\../..\\classification\\classifiers.py:520\u001b[0m, in \u001b[0;36mDeepClassifier.fit\u001b[1;34m(self, fabric, num_epochs, lr, weight_decay, verbose, validation_step, optimizer)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fabric\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m    519\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs[:, :, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_cutoff], labels\n\u001b[1;32m--> 520\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    522\u001b[0m fabric\u001b[38;5;241m.\u001b[39mbackward(loss)\n",
      "Cell \u001b[1;32mIn[96], line 29\u001b[0m, in \u001b[0;36mDiffusionClf.classify\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 29\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf(x)\n\u001b[0;32m     31\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[96], line 20\u001b[0m, in \u001b[0;36mDiffusionClf.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m cond \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m,x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x,cond],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m time_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtime_embbeder(t)\n\u001b[0;32m     22\u001b[0m time_embed \u001b[38;5;241m=\u001b[39m repeat(time_embed,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb t -> b t l\u001b[39m\u001b[38;5;124m\"\u001b[39m,l\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slc_clf.fit(fabric=fabric,\n",
    "\t\t\t num_epochs=150,\n",
    "\t\t\t lr=1E-3,\n",
    "\t\t\t weight_decay=1E-4,\n",
    "\t\t\t verbose=True,\n",
    "\t\t\t optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
